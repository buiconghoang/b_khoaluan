{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "from sklearn.utils import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib   import pyplot as plt\n",
    "from math import pi\n",
    "import pickle\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test hàm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Lấy danh sách label trong tập train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_labels(train_path):\n",
    "    p=Path(train_path)\n",
    "    path_file =[] # return absolute path\n",
    "    labels = []\n",
    "    if p.is_dir():\n",
    "        for file in p.iterdir():\n",
    "            if file.is_dir():\n",
    "                path_file.append(file)\n",
    "                \n",
    "        for path in path_file:\n",
    "            label = path.parts[-1]\n",
    "            labels.append(label)\n",
    "#             print(path.parts[-1])\n",
    "    else:\n",
    "        raise ValueError(f\"{train_path} is not a directory!!\")\n",
    "    return labels\n",
    "\n",
    "\n",
    "# a= get_labels(r\"D:\\DatasetJapanese\\data_use_kl\\00753.png\") // error\n",
    "# print(a)    \n",
    "\n",
    "# b= get_labels(r\"D:\\DatasetJapanese\\data_use_kl\")\n",
    "# print((b[0])) #label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GenerateData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE=64\n",
    "def rotate_images(X_imgs, start_angle=45, end_angle=-45, n_images=2):\n",
    "    X_rotate = []\n",
    "#     iterate_at = (end_angle - start_angle) / (n_images - 1)\n",
    "    do = np.random.uniform(end_angle,start_angle,n_images)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (None, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    radian = tf.placeholder(tf.float32, shape = (len(X_imgs)))\n",
    "    tf_img = tf.contrib.image.rotate(X, radian)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for index in range(n_images):\n",
    "            degrees_angle = do[index]\n",
    "            radian_value = degrees_angle * pi / 180  # Convert to radian\n",
    "            radian_arr = [radian_value] * len(X_imgs)\n",
    "            rotated_imgs = sess.run(tf_img, feed_dict = {X: X_imgs, radian: radian_arr})\n",
    "            X_rotate.extend(rotated_imgs)\n",
    "\n",
    "    X_rotate = np.array(X_rotate, dtype = np.float32)\n",
    "    return X_rotate\n",
    "\n",
    "\n",
    "def central_scale_images(X_imgs, scales=np.round(np.random.uniform(0.8,1,3),2)):\n",
    "    # Various settings needed for Tensorflow operation\n",
    "    \n",
    "    boxes = np.zeros((len(scales), 4), dtype = np.float32)\n",
    "    for index, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - 0.5 * scale # To scale centrally\n",
    "        x2 = y2 = 0.5 + 0.5 * scale\n",
    "        boxes[index] = np.array([y1, x1, y2, x2], dtype = np.float32)\n",
    "    box_ind = np.zeros((len(scales)), dtype = np.int32)\n",
    "    crop_size = np.array([IMAGE_SIZE, IMAGE_SIZE], dtype = np.int32)\n",
    "    \n",
    "    X_scale_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    # Define Tensorflow operation for all scales but only one base image at a time\n",
    "    tf_img = tf.image.crop_and_resize(X, boxes, box_ind, crop_size)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for img_data in X_imgs:\n",
    "            batch_img = np.expand_dims(img_data, axis = 0)\n",
    "            scaled_imgs = sess.run(tf_img, feed_dict = {X: batch_img})\n",
    "            X_scale_data.extend(scaled_imgs)\n",
    "    \n",
    "    X_scale_data = np.array(X_scale_data, dtype = np.float32)\n",
    "    return X_scale_data\n",
    "def generate_data(X_imgs):\n",
    "    \n",
    "    rotated_imgs = rotate_images(X_imgs)\n",
    "    scaled_imgs =central_scale_images(rotated_imgs)\n",
    "    \n",
    "    result = np.concatenate((X_imgs,rotated_imgs,scaled_imgs,),axis=0)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train(train_path,img_size):\n",
    "    images=[]\n",
    "    labels=[]\n",
    "    img_names=[]\n",
    "    cls = []\n",
    "    classes = get_labels(train_path)\n",
    "    \n",
    "    \n",
    "    for fields in classes:\n",
    "        index = classes.index(fields)\n",
    "        # print(\"doc file {} (index: {})\".format(fields,index))\n",
    "        path = os.path.join(train_path,fields,'*')\n",
    "#         print(f\"path: {path}\")\n",
    "        files = glob.glob(path) #return list of path names that match path =path;\n",
    "#         print(\"file: \",files)\n",
    "        \n",
    "        for fi in files:\n",
    "            img = cv2.imread(fi);\n",
    "            img= cv2.resize(img,(img_size,img_size))\n",
    "            img=img.astype(np.float32)\n",
    "            img=np.multiply(img, 1.0/255.0)\n",
    "            img = np.reshape(img,(-1,64,64,3))\n",
    "            data_is_generated = generate_data(img) #shpae [num_img,img_size,img_size,channel]\n",
    "            filename_base = os.path.basename(fi)\n",
    "            for i in range (data_is_generated.shape[0]):\n",
    "                images.append(data_is_generated[0])\n",
    "                label = np.zeros(len(classes))\n",
    "                label[index]=1\n",
    "                labels.append(label)\n",
    "                img_names.append(filename_base)\n",
    "                cls.append(fields)\n",
    "          \n",
    "  \n",
    "    images=np.array(images)\n",
    "    labels=np.array(labels)\n",
    "    img_names=np.array(img_names)\n",
    "    cls = np.array(cls)\n",
    "    \n",
    "    return images,labels,img_names,cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # test load_train function\n",
    "# images,labels,img_names,cls= load_train(\"D:\\DatasetJapanese\\data_katagana\\katakana_test\",64)\n",
    "# print(labels[0],img_names[0],cls[0])\n",
    "# img = plt.imshow(images[0])\n",
    "# print(images.shape) # (total_images,img_size,img_size,channels)\n",
    "# print(images.shape[0])# total_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet (object):\n",
    "    \n",
    "    def __init__(self,images,labels,img_names,cls):\n",
    "        # print(\"size: {} \".format(images.shape[0]))\n",
    "        self._num_examples=images.shape[0]\n",
    "        \n",
    "        self._images= images\n",
    "        self._labels=labels\n",
    "        self._img_names=img_names\n",
    "        self._cls = cls;\n",
    "        \n",
    "        self._epochs_done = 0\n",
    "        self._index_in_epoch = 0\n",
    "        \n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "    \n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "    \n",
    "    @property\n",
    "    def img_names(self):\n",
    "        return self._img_names\n",
    "    \n",
    "    @property\n",
    "    def cls(self):\n",
    "        return self._cls\n",
    "    \n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "    \n",
    "    @property\n",
    "    def epochs_done(self):\n",
    "        return self._epochs_done\n",
    "\n",
    "\n",
    "    def next_batch(self,batch_size):\n",
    "        start=self._index_in_epoch\n",
    "        self._index_in_epoch +=batch_size\n",
    "        \n",
    "        if(self._index_in_epoch >self.num_examples):\n",
    "            # sau moi epoch can phai shuffle lai vi tri de du lieu duoc ngau nhien, tranh lap lai batchsize giong nhau\n",
    "            self._images,self._labels,self._img_names,self._cls = shuffle(self._images,self._labels,self._img_names,self._cls)\n",
    "            \n",
    "            self._epochs_done +=1\n",
    "            start=0\n",
    "            self._index_in_epoch=batch_size\n",
    "            assert batch_size <= self._num_examples\n",
    "            \n",
    "        end = self._index_in_epoch\n",
    "        \n",
    "        return self._images[start:end], self._labels[start:end], self._img_names[start:end], self._cls[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_train_sets(train_path,image_size,test_size, validation_size):\n",
    "    classes = get_labels(train_path)\n",
    "    class DataSets(object):pass\n",
    "    \n",
    "    data_sets = DataSets();\n",
    "    \n",
    "    images,labels,img_names,cls = load_train(train_path,image_size)\n",
    "    images,labels,img_names,cls = shuffle(images,labels,img_names,cls)\n",
    "    \n",
    "    if isinstance(test_size,float) or isinstance(test_size,float) or test_size<1 or validation_size<1 :\n",
    "        test_size=int(images.shape[0] * test_size) # total_images * validation_size\n",
    "        validation_size = test_size + int(images.shape[0] * validation_size)\n",
    "        # print(\"images: {}\".format(images.shape[0]))\n",
    "        # print(\"valid: {}\".format(validation_size))\n",
    "        \n",
    "    test_images = images[:test_size]\n",
    "    test_labels = labels[:test_size]\n",
    "    test_img_names = img_names[:test_size]\n",
    "    test_cls = cls[:test_size]\n",
    "    \n",
    "    validation_images = images[test_size:validation_size]\n",
    "    validation_labels = labels[test_size:validation_size]\n",
    "    validation_img_names = img_names[test_size:validation_size]\n",
    "    validation_cls = cls[test_size:validation_size]\n",
    "    \n",
    "    train_images = images[validation_size:]\n",
    "    train_labels = labels[validation_size:]\n",
    "    train_img_names = img_names[validation_size:]\n",
    "    train_cls = cls[validation_size:]\n",
    "    \n",
    "    data_sets.test = DataSet(test_images,test_labels,test_img_names,test_cls)\n",
    "    data_sets.train= DataSet(train_images,train_labels,train_img_names,train_cls)\n",
    "    data_sets.valid = DataSet(validation_images,validation_labels,validation_img_names,validation_cls)\n",
    "    \n",
    "    return data_sets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# validation_size = 0.22\n",
    "# train_path='D:\\DatasetJapanese\\\\data_katagana\\katakana_test'\n",
    "\n",
    "# data=read_train_sets(\"D:\\DatasetJapanese\\data_katagana\\katakana_test\",image_size=10,validation_size=validation_size)\n",
    "# images,labels,img_names,cls = load_train(train_path,64)\n",
    "# print(data.train.images.shape)\n",
    "# print(data.valid.images.shape)\n",
    "# print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data = read_train_sets(r\"D:\\DatasetJapanese\\data_katagana\\minitest\",64,0.2,0.1)\n",
    "# class DataCompression(object):\n",
    "#     def __init__(self,data):\n",
    "#         self.train = data.train\n",
    "#         self.valid = data.valid\n",
    "#         self.test = data.test\n",
    "        \n",
    "# data_train = DataCompression(data)\n",
    "# with open(\"train.file\", \"wb\") as f:\n",
    "#     pickle.dump(data_train, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6468, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.02636569,  2.78489282, -4.77268915, -8.18047981, -3.42725496])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.uniform(10,-10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
