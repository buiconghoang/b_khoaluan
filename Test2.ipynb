{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import math\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "path_model = \"./model\"\n",
    "\n",
    "\n",
    "labels = ['a_h', 'a_k', 'chi_h', 'chi_k', 'e_h', 'e_k', 'fu_h', 'fu_k', 'ha_h', 'ha_k',\n",
    "         'he_h', 'he_k', 'hi_h', 'hi_k', 'ho_h', 'ho_k', 'i_h', 'i_k', 'ka_h', 'ka_k',\n",
    "         'ke_h', 'ke_k', 'ki_h', 'ki_k', 'ko_h', 'ko_k', 'ku_h', 'ku_k', 'ma_h', 'ma_k',\n",
    "         'me_h', 'me_k', 'mi_h', 'mi_k', 'mo_h', 'mo_k', 'mu_h', 'mu_k', 'na_h', 'na_k',\n",
    "         'ne_h', 'ne_k', 'ni_h', 'ni_k', 'no_h', 'no_k', 'nu_h', 'nu_k', 'n_h', 'n_k', \n",
    "         'o_h', 'o_k', 'ra_h', 'ra_k', 're_h', 're_k', 'ri_h', 'ri_k', 'ro_h', 'ro_k',\n",
    "         'ru_h', 'ru_k', 'sa_h', 'sa_k', 'se_h', 'se_k', 'shi_h', 'shi_k', 'so_h', 'so_k',\n",
    "         'su_h', 'su_k', 'ta_h', 'ta_k', 'te_h', 'te_k', 'to_h', 'to_k', 'tsu_h', 'tsu_k',\n",
    "         'u_h', 'u_k', 'wa_h', 'wa_k', 'wo_h', 'wo_k', 'ya_h', 'ya_k', 'yo_h', 'yo_k', 'yu_h', 'yu_k',]\n",
    "\n",
    "alphabet_dicts={'a_h': ' あ', 'a_k': 'ア ', 'chi_h': 'ち ', 'chi_k': 'チ ', 'e_h': 'え ', 'e_k': ' エ', 'fu_h': 'ふ ', 'fu_k': 'フ ',\n",
    "       'ha_h': 'は ', 'ha_k': ' ハ', 'he_h': ' へ', 'he_k': 'ヘ ', 'hi_h': 'ひ ', 'hi_k': ' ヒ', 'ho_h': 'ほ ', 'ho_k': 'ホ ',\n",
    "       'i_h': ' い', 'i_k': 'キ ', 'ka_h': 'か', 'ka_k': ' カ', 'ke_h': 'け ', 'ke_k': ' ケ', 'ki_h': ' き', 'ki_k': 'キ ',\n",
    "       'ko_h': ' こ', 'ko_k': 'コ ', 'ku_h': 'く ', 'ku_k': ' ク', 'ma_h': ' ま', 'ma_k': ' マ', 'me_h': 'め ', 'me_k': 'メ ', \n",
    "       'mi_h': ' み', 'mi_k': ' ミ', 'mo_h': ' も', 'mo_k': ' モ', 'mu_h': ' む', 'mu_k': 'ム ', 'n_h': 'ン', 'n_k': 'ン ',\n",
    "       'na_h': 'な ', 'na_k': ' ナ', 'ne_h': 'ね ', 'ne_k': 'ネ ', 'ni_h': 'に ', 'ni_k': 'ニ ', 'no_h': ' の', 'no_k': ' ノ',\n",
    "       'nu_h': ' ぬ', 'nu_k': ' ヌ', 'o_h': ' お', 'o_k': 'オ ', 'ra_h': ' ら', 'ra_k': 'ラ ', 're_h': 'れ ', 're_k': 'レ ',\n",
    "       'ri_h': 'り ', 'ri_k': ' リ', 'ro_h': ' ろ', 'ro_k': ' ロ', 'ru_h': ' る', 'ru_k': 'ル ', 'sa_h': ' さ', 'sa_k': 'サ ', \n",
    "       'se_h': 'せ ', 'se_k': 'セ ', 'shi_h': 'し ', 'shi_k': 'シ ', 'so_h': 'そ ', 'so_k': 'ソ ', 'su_h': 'す ', 'su_k': ' ス',\n",
    "       'ta_h': ' た', 'ta_k': 'タ ', 'te_h': 'て ', 'te_k': 'テ ', 'to_h': 'と ', 'to_k': ' ト', 'tsu_h': 'つ ', 'tsu_k': 'ツ',\n",
    "       'u_h': ' う', 'u_k': ' ウ', 'wa_h': 'わ ', 'wa_k': 'ワ ', 'wo_h': ' を', 'wo_k': 'ヲ ', 'ya_h': 'や ', 'ya_k': 'ヤ ', \n",
    "       'yo_h': 'よ ', 'yo_k': ' ヨ', 'yu_h': ' ゆ', 'yu_k': 'ユ '}\n",
    "         \n",
    "\n",
    "def get_japanese_alphabet(index):\n",
    "    index =int(index)\n",
    "    key = labels[index]\n",
    "    \n",
    "    return alphabet_dicts[key]\n",
    "          \n",
    "def convert_image_to_input(file_image):\n",
    "    img_size = 64\n",
    "    num_channels = 3\n",
    "    file_image = str(file_image)\n",
    "    images = []\n",
    "    img = cv2.imread(file_image)\n",
    "    \n",
    "    \n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    print(f\"convert_image_to_input, img_shape: {img.shape}\")\n",
    "#     cv2.imwrite(file_image, img)\n",
    "\n",
    "#     img = cv2.imread(file_image)\n",
    "\n",
    "##     convert image input\n",
    "    for i in range(64):\n",
    "        for j in range(64):\n",
    "            for k in range(3):\n",
    "    #             print(f\"i: {i}, j {j}, k {k}, {a[i,j,:]}\")\n",
    "                if (np.all(img[i,j,k]>= (0,0,250))):\n",
    "                    gray_color = np.random.randint(250,255,3)\n",
    "                    img[i,j,:]=gray_color\n",
    "    #                 print(f\"i: {i}, j {j}, k {k}, {a[i,j,:]}\")\n",
    "                    break;\n",
    "    \n",
    "#                 if np.all(img[i,j,k]== (0,0,0)):\n",
    "#                     black_color = np.random.randint(0,30,3)\n",
    "#                     img[i,j,:]=black_color\n",
    "#                     break;\n",
    "    # take image to center              \n",
    "    img= cv2.resize(img,(40,40))\n",
    "    img =np.pad(img, ((12, 12), (12, 12),(0,0)), 'constant', constant_values=(0))\n",
    "    cv2.imwrite(\"iw1.png\",img)\n",
    "    #     cv2.imshow(\"img\",img)\n",
    "    #     cv2.waitKey(0)\n",
    "    #     cv2.destroyAllWindows()\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    img = np.multiply(img, 1.0 / 255.0)\n",
    "\n",
    "    images.append(img)\n",
    "\n",
    "    images = np.array(images)\n",
    "    #     print(images.shape)\n",
    "\n",
    "    x_batch = images.reshape(-1, img_size, img_size, num_channels)\n",
    "    # print(x_batch.shape)\n",
    "\n",
    "    return x_batch\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "class Test(object):\n",
    "    def __init__(self, path_img):\n",
    "        self.sess = tf.Session()\n",
    "        path_model_last = tf.train.latest_checkpoint(\".\\model\")\n",
    "        saver = tf.train.import_meta_graph(path_model_last +\".meta\", clear_devices=True)\n",
    "#         print(\"init__: \",path_model)\n",
    "#         p = Path(path_model)\n",
    "#         print(p.absolute())\n",
    "        saver.restore(self.sess, path_model_last)\n",
    "\n",
    "        self.graph = tf.get_default_graph()\n",
    "        self.keep_prob = self.graph.get_tensor_by_name(\"inputs/keep_prob:0\")\n",
    "        self.x = self.graph.get_tensor_by_name(\"inputs/x:0\")\n",
    "    \n",
    "        self.path_img = str(path_img)\n",
    "    def listOfTensor(self):\n",
    "        for tensor in self.graph.as_graph_def().node:\n",
    "            print(tensor.name)\n",
    "#         for op in self.graph.get_operations():\n",
    "#             print (str(op.name)) \n",
    "\n",
    "    def print_layer(self, ):\n",
    "       \n",
    "        \n",
    "        x_batch = convert_image_to_input(self.path_img)\n",
    "        layer = self.graph.get_tensor_by_name(\"conv4/conv4:0\")\n",
    "        \n",
    "        layer = self.sess.run(layer,feed_dict={self.x:x_batch, self.keep_prob:1.0})\n",
    "        #prin(layer.shpae) #[?,64,64,channel] ?: amount input\n",
    "        num_filters = layer.shape[3]\n",
    "        \n",
    "        num_grids = math.ceil(math.sqrt(num_filters))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_grids, num_grids)\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i<num_filters:\n",
    "                img = layer[0, :, :, i]\n",
    "\n",
    "                ax.imshow(img, interpolation='nearest', cmap='binary')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "        plt.show()\n",
    "    \n",
    "    def print_weight(self):\n",
    "        w= self.graph.get_tensor_by_name(\"conv1/weights/conv1_weights:0\")\n",
    "        print(w.shape) #(3, 3, 3, 32) width, height, deep, channel\n",
    "        w=self.sess.run(w)\n",
    "        print(w[:,:,0,0])\n",
    "        w_min = np.min(w)\n",
    "        w_max=np.max(w)\n",
    "        num_filters = w.shape[3]\n",
    "        \n",
    "        num_grids = math.ceil(math.sqrt(num_filters)) # lấy trần\n",
    "        \n",
    "        fig, axes = plt.subplots(num_grids, num_grids)\n",
    "        for i, ax in enumerate(axes.flat):\n",
    "            if i<num_filters:\n",
    "                img = w[:, :, 0, i]\n",
    "\n",
    "                ax.imshow(img, vmin=w_min, vmax=w_max,\n",
    "                          interpolation='nearest', cmap='binary' ) #cmap: seismic, binary\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "    \n",
    "        plt.show()\n",
    "    def predict(self):\n",
    "        \n",
    "        y_pred = self.graph.get_tensor_by_name(\"Test/y_pred:0\")\n",
    "\n",
    "        \n",
    "        # y_true = graph.get_tensor_by_name(\"y_true:0\")\n",
    "\n",
    "        x_batch = convert_image_to_input(self.path_img)\n",
    "        result = self.sess.run(y_pred, feed_dict={self.x: x_batch, self.keep_prob:1.0})\n",
    "#         print(result)\n",
    "#         print(np.argmax(result,1 ))\n",
    "#         print(np.max(result))\n",
    "        index_result = np.argmax(result,1)\n",
    "        acc =np.max(result)\n",
    "        alphabet_japan = get_japanese_alphabet(index_result)\n",
    "        \n",
    "        return [alphabet_japan,acc]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_image = r\"D:\\DatasetJapanese\\data_katagana\\katakana_test\\a_k\\01400.png\"\n",
    "file_2 = r\".\\image\\a.png\"\n",
    "p1= r\".\\image\\a_den.png\"\n",
    "p11=r\".\\image\\ak_ok.png\"\n",
    "p2=r\"D:\\DatasetJapanese\\data_use_kl\\ka_h\\etl7_1046.png\"\n",
    "p3=r\"C:\\Users\\BuiHoang\\a_LearnPython\\iw1.png\"\n",
    "p4=r\"C:\\Users\\BuiHoang\\a_LearnPython\\img3.png\"\n",
    "\n",
    "# lap huy\n",
    "p1=r\"D:\\Hoang\\test_generate_data\\a.png\"\n",
    "t=Test(p1)\n",
    "\n",
    "# t.listOfTensor()\n",
    "\n",
    "pred = t.predict()\n",
    "print(pred)\n",
    "\n",
    "t.print_layer()\n",
    "t.print_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dicts={'a_h': ' あ', 'a_k': 'ア ', 'chi_h': 'ち ', 'chi_k': 'チ ', 'e_h': 'え ', 'e_k': ' エ', 'fu_h': 'ふ ', 'fu_k': 'フ ',\n",
    "       'ha_h': 'は ', 'ha_k': ' ハ', 'he_h': ' へ', 'he_k': 'ヘ ', 'hi_h': 'ひ ', 'hi_k': ' ヒ', 'ho_h': 'ほ ', 'ho_k': 'ホ ',\n",
    "       'i_h': ' い', 'i_k': 'キ ', 'ka_h': 'か', 'ka_k': ' カ', 'ke_h': 'け ', 'ke_k': ' ケ', 'ki_h': ' き', 'ki_k': 'キ ',\n",
    "       'ko_h': ' こ', 'ko_k': 'コ ', 'ku_h': 'く ', 'ku_k': ' ク', 'ma_h': ' ま', 'ma_k': ' マ', 'me_h': 'め ', 'me_k': 'メ ', \n",
    "       'mi_h': ' み', 'mi_k': ' ミ', 'mo_h': ' も', 'mo_k': ' モ', 'mu_h': ' む', 'mu_k': 'ム ', 'n_h': 'ン', 'n_k': 'ン ',\n",
    "       'na_h': 'な ', 'na_k': ' ナ', 'ne_h': 'ね ', 'ne_k': 'ネ ', 'ni_h': 'に ', 'ni_k': 'ニ ', 'no_h': ' の', 'no_k': ' ノ',\n",
    "       'nu_h': ' ぬ', 'nu_k': ' ヌ', 'o_h': ' お', 'o_k': 'オ ', 'ra_h': ' ら', 'ra_k': 'ラ ', 're_h': 'れ ', 're_k': 'レ ',\n",
    "       'ri_h': 'り ', 'ri_k': ' リ', 'ro_h': ' ろ', 'ro_k': 'ﾛ', 'ru_h': ' る', 'ru_k': 'ル ', 'sa_h': ' さ', 'sa_k': 'サ ', \n",
    "       'se_h': 'せ ', 'se_k': 'セ ', 'shi_h': 'し ', 'shi_k': 'シ ', 'so_h': 'そ ', 'so_k': 'ソ ', 'su_h': 'す ', 'su_k': ' ス',\n",
    "       'ta_h': ' た', 'ta_k': 'タ ', 'te_h': 'て ', 'te_k': 'テ ', 'to_h': 'と ', 'to_k': ' ト', 'tsu_h': 'つ ', 'tsu_k': 'ツ',\n",
    "       'u_h': ' う', 'u_k': ' ウ', 'wa_h': 'わ ', 'wa_k': 'ワ ', 'wo_h': ' を', 'wo_k': 'ヲ ', 'ya_h': 'や ', 'ya_k': 'ヤ ', \n",
    "       'yo_h': 'よ ', 'yo_k': ' ヨ', 'yu_h': ' ゆ', 'yu_k': 'ユ '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
